#!/bin/bash
set -e
#
# Script run on the dockerd host to start the E2E Container.

function printLicense {
  cat <<-"EOF"
Copyright © 2012-2017 Raytheon BBN Technologies, Inc.
Cambridge, MA USA
All rights reserved.

This program and associated material contains information whose export or 
disclosure to Non-U.S. Persons, wherever located, is subject to the Export 
Administration Regulations (EAR) (15 C.F.R. §730-774). Specifically,
Raytheon BBN Technologies conducted an internal review and determined that this 
information is export controlled as EAR99. Exports contrary to U.S. law are
prohibited.

As part of the DEFT effort, BBN SERIF(TM) is being provided with Government
Purpose Rights. Please see DFARS 252.227-7014 for details.

Various third-party libraries are incorporated into this application. Please
see THIRD-PARTY.txt for a list of the libraries and their licenses.

-------------------------------------------------------------------------------

EOF
}

function help {
cat <<EOF
a2kd

$1 <a2kd_config file> <input_directory> <num_partitions> <num_executors>

The $1 program executes an A2KD analysis over the provided corpus using the
parameters specified on the command line and in the configuration file.

This program requires access to the HADOOP and the Spark configuration
directories in order to function properly. If the standard environment
variables (HADOOP_CONF_DIR and SPARK_CONF_DIR) are not defined, the program
wil look for them at /etc/{spark,hadoop}/conf and at $HOME/{hadoop,spark}/conf.
If these directories cannot be found and the environment variables are not defined,
the program will fail. If you have these directories in a non-standard location, the
environment variables can easily be defined on the command line:

SPARK_CONF_DIR=/share/spark/conf HADOOP_CONF_DIR=/share/hadoop/conf $1 a2kd_config input 5 5

The parameters that must be defined in the configuration file are documented therein.

EOF
[ $# -eq 2 ] && exit $2
}

function errexit {
   ( >&2 echo "$1")
   logger -p user.error "$1"
   exit 1
}

# check for help
if [ $# -eq 0 -o "$1" = "-h" -o "$1" = "--help" ]; then
  help $(basename $0) 0
fi
if [ $# -ne 4 ]; then
  ( >&2 echo "ERROR: incorrect number of parameters")
  help $(basename $0) 1
fi

# Set up identity variables
IFS='~'
UI="$(id -u)"
UN="$(echo -n "$(id -un)" | tr "[:space:]" "_")
GI="$(id -g)"
GN="$(echo -n "$(id -gn)" | tr "[:space:]" "_")
unset IFS

# Check for or set SPARK_CONF_DIR
if [ ! "${SPARK_CONF_DIR}" ] ; then
  if [ "${SPARK_HOME}" ] ; then
    if [ -d ${SPARK_HOME}/conf -a -r ${SPARK_HOME}/conf ] ; then
      SPARK_CONF_DIR=${SPARK_HOME}/conf
    fi
  fi
  for SCD in /etc/spark/conf ~/spark/conf /var/lib/spark/conf; do
    if [ -d $SCD -a -r $SCD ]; then
      SPARK_CONF_DIR="$SCD"
      break
    fi
  done
fi
if [ ! "${SPARK_CONF_DIR}" ] ; then
  errexit "ERROR: SPARK_CONF_DIR is not defined and cannot be guessed"
fi
if [ ! -e "${SPARK_CONF_DIR}" ] ; then
  errexit "ERROR: SPARK_CONF_DIR does not exist"
fi
if [ ! -d "${SPARK_CONF_DIR}" ] ; then
  errexit "ERROR: SPARK_CONF_DIR is not a directory"
fi
if [ ! -r "${SPARK_CONF_DIR}" ] ; then
  errexit "ERROR: SPARK_CONF_DIR (${SPARK_CONF_DIR}) found but is not readable"
fi
# Check for or set HADOOP_CONF_DIR
if [ ! "${HADOOP_CONF_DIR}" ] ; then
  if [ "${HADOOP_HOME}" ] ; then
    if [ -d "$HADOOP_HOME/conf" -a -r "$HADOOP_HOME/conf" ] ; then
      HADOOP_CONF_DIR="$HADOOP_HOME/conf"
    fi
  fi
  for HCD in /etc/hadoop/conf ~/hadoop/conf /var/lib/hadoop/conf; do
    if [ -d $SCD -a -r $SCD ]; then
      HADOOP_CONF_DIR="$SCD"
      break
    fi
  done
fi
if [ ! "${HADOOP_CONF_DIR}" ] ; then
  errexit "ERROR: HADOOP_CONF_DIR is not defined and cannot be guessed"
fi
if [ ! -e "${HADOOP_CONF_DIR}" ] ; then
  errexit "ERROR: HADOOP_CONF_DIR does not exist"
fi
if [ ! -d "${HADOOP_CONF_DIR}" ] ; then
  errexit "ERROR: HADOOP_CONF_DIR is not a directory"
fi
if [ ! -r "${HADOOP_CONF_DIR}" ] ; then
  errexit "ERROR: HADOOP_CONF_DIR (${HADOOP_CONF_DIR}) found but is not readable"
fi

# $1 a2kd config file
if [ ! -f "${1}" -o ! -r "${1}" ] ; then
  errexit "ERROR: A2KD Configuration File \"${1}\" does not exist, is not a file, or is not readable"
fi
IFS='%'
a2kd_config="$(readlink -f $"${1}")"
unset IFS
echo $a2kd_config "$a2kd_config"
# $2 input data directory
if [ ! -d "${2}" -o ! -r "${2}" ] ; then
  errexit "ERROR: A2KD Input Data Directory \"${2}\" does not exist, is not a directory, or is not readable"
fi
IFS='%'
a2kd_input_dir="$(readlink -f $"${2}")" # also convert to an absolute path name
unset IFS
echo $a2kd_input_dir "$a2kd_input_dir"
# $3 partitions
if ! [[ "${3}" =~ ^[0-9]+$ ]] ; then
  errexit "ERROR: number of partitions value \"${3}\" is not an integer value"
fi
a2kd_num_partitions="$3"
# $4 executors
if ! [[ "${4}" =~ ^[0-9]+$ ]] ; then
  errexit "ERROR: number of executors value \"${4}\" is not an integer value"
fi
a2kd_num_executors="$4"

# read and parse the configuration file for the values of interest
while read line; do
    [[ "$line" =~ ^([[:space:]]*<entry[[:space:]]+key=\")([^\"]+)(\"[[:space:]]*>)([^<]*)(<[[:space:]]*/entry[[:space:]]*>) ]] && declare ${BASH_REMATCH[2]}=${BASH_REMATCH[4]}
done < "$a2kd_config"

[ "$shared_top" ] || errexit "ERROR: the \"shared_top\" variable is not defined in the \"$a2kd_config\" file"
if [ ! -d "$shared_top" -o ! -r "$shared_top" ] ; then
  errexit "ERROR: The A2KD Shared Directory \"$shared_top\" does not exist, is not a directory, or is not readable"
fi

a2kd_output_dir="$(readlink -f $"${PWD}")"

if [ "$kb_report_output_dir" ]; then
  if [[ $kb_report_output_dir != /* ]] ; then
    kb_report_output_dir=$shared_top/$kb_report_output_dir
  fi
  mkdir -p $kb_report_output_dir/$corpus_id
fi
if [[ "$gather_statistics" == "true" ]]; then
  if [ ! "$stats_file_path" ] ; then
    errexit "ERROR: gather_statistics is set to true in ${a2kd_config}, but stats_file_path is not set"
  fi
  if [[ "$stats_file_path" != /* ]] ; then
    stats_file_path=$shared_top/$stats_file_path
  fi
  if [ ! -e "$stats_file_path" ]; then
    mkdir -p "$(dirname $stats_file_path)"
    touch "$stats_file_path"
  else
    [ -f "$stats_file_path" ] || errexit "ERROR: the statistics file path $stats_file_path exists but is not a file"
    [ -w "$stats_file_path" ] || errexit "ERROR: the statistics file path $stats_file_path exists but is not writable"
  fi
  chmod 777 "$stats_file_path"
fi
find "$kb_report_output_dir" -type d -exec chmod 777 {} \;

# print the license
printLicense
# Next Phase - start the container and continue processing
${DOCKER_CMD:-docker} run -it --rm --name "$corpus_id" \
  -e LOCAL_USER_ID=$UI \
  -e LOCAL_USER_NAME="$UN" \
  -e LOCAL_GROUP_ID=$GI \
  -e LOCAL_GROUP_NAME="$GN" \
  -e master=${master:-yarn} \
  -e deploy_mode=${deploy_mode:-cluster} \
  -e shared_top="$shared_top" \
  -e a2kd_config="$a2kd_config" \
  -v "$HADOOP_CONF_DIR":/conf/hadoop \
  -v "$SPARK_CONF_DIR":/conf/spark \
  -v "$shared_top":/sharedData \
  -v "$a2kd_config":/a2kd_config \
  -v "$a2kd_input_dir":/input \
  -v "$a2kd_output_dir":/output \
  -p :4040 \
  deft/a2kd a2kd.sh $2 $3 $4

